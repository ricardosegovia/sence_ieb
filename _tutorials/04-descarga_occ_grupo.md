---
layout: default
title: "Descarga y limpieza de datos de ocurrencia desde GBIF"
description: "Flujo de trabajo en R para descargar, combinar y limpiar registros de ocurrencia usando datos de GBIF."
section: datos
order: 30
---

# Descarga y limpieza de datos de ocurrencia desde GBIF

Este tutorial muestra cÃ³mo automatizar la descarga de registros de ocurrencia desde **GBIF**, combinarlos y realizar una limpieza bÃ¡sica de coordenadas utilizando el paquete **CoordinateCleaner**.  
El flujo estÃ¡ diseÃ±ado para obtener datos de especies **nativas o endÃ©micas arbÃ³reas de Chile**, recortar el conjunto al territorio continental y eliminar coordenadas errÃ³neas.

---

## ğŸ”¹ 1. Cargar librerÃ­as necesarias

```r
library(readxl)
library(tidyr)
library(dplyr)
library(rgbif)
source("R/combina_gbif_data.r")
library(sf)
library(rnaturalearth)
library(CoordinateCleaner)
```

> ğŸ’¡ AsegÃºrate de que el script `combina_gbif_data.r` contenga la funciÃ³n `unificar_y_combinar_datasets()` que combina los archivos descargados.

---

## ğŸ”¹ 2. Configurar credenciales y cargar el catÃ¡logo

```r
# user <- "tu.usuario.gbif"      # Reemplaza con tu usuario GBIF
# pwd  <- "tu.contraseÃ±a.gbif"   # Reemplaza con tu contraseÃ±a GBIF
# email <- "tu.correo"

# 1. Cargar el catÃ¡logo local de especies
cat <- read_excel("/ruta/a/Catalogo.xlsx")

# 2. Filtrar especies vÃ¡lidas, determinadas y de hÃ¡bito arbÃ³reo
species_list <- cat %>%
  filter(determined == TRUE) %>%
  filter(status %in% c("EndÃ©mica", "Nativa") | is.na(status)) %>%
  filter(plant_habit_1 == "Ãrbol") %>%
  pull(scientific_name) %>%
  unique()
```

---

## ğŸ”¹ 3. Descargar datos de GBIF por especie

```r
datasets_list <- list()

for (species_name in species_list) {
  cat("Procesando:", species_name, "\n")

  # Obtener taxonKey
  taxon_info <- name_backbone(species_name)
  taxon_key <- taxon_info$usageKey

  # Definir descarga desde GBIF
  gbif_download <- occ_download(
    pred("taxonKey", taxon_key),
    pred("country", "CL"),
    pred("hasGeospatialIssue", FALSE),
    pred("hasCoordinate", TRUE),
    pred("occurrenceStatus", "PRESENT"),
    pred_gte("year", 2000),
    user = user, pwd = pwd, email = email,
    format = "SIMPLE_CSV"
  )

  # Esperar y descargar resultados
  occ_download_wait(gbif_download)
  data_downloaded <- occ_download_get(gbif_download) |> occ_download_import()

  # Almacenar
  datasets_list[[species_name]] <- data_downloaded
  cat("Completado:", species_name, "\n")
}
```

---

## ğŸ”¹ 4. Combinar y exportar los datos

```r
# Estandarizar columnas antes de combinar
datasets_list_clean <- lapply(datasets_list, function(df) {
  df %>%
    mutate(
      catalogNumber = as.character(catalogNumber),
      institutionCode = as.character(institutionCode)
    )
})

# Combinar datasets
combined_data <- unificar_y_combinar_datasets(datasets_list_clean)

# Exportar
write.csv(combined_data, "data/combined_gbif_data.csv", row.names = FALSE)
```

---

## ğŸ”¹ 5. Limpieza y recorte espacial

```r
combined_data <- read.csv("data/combined_gbif_data.csv") %>%
  select(
    scientificName, catalogNumber, institutionCode,
    decimalLatitude, decimalLongitude, year, month, day
  ) %>%
  filter(!is.na(decimalLatitude) & !is.na(decimalLongitude)) %>%
  distinct()

# Convertir a objeto espacial
occs_sf <- st_as_sf(combined_data, coords = c("decimalLongitude", "decimalLatitude"), crs = 4326)

# Descargar y recortar capa de Chile
chile <- ne_countries(scale = "medium", country = "Chile", returnclass = "sf")
chile_continental <- st_crop(chile, xmin = -76, xmax = -66, ymin = -56, ymax = -17)

# IntersecciÃ³n espacial
occs_crop <- st_filter(occs_sf, chile_continental)

# Extraer coordenadas de vuelta al data.frame
occs_crop_df <- occs_crop %>%
  mutate(
    decimalLongitude = st_coordinates(geometry)[, 1],
    decimalLatitude  = st_coordinates(geometry)[, 2]
  ) %>%
  st_drop_geometry()
```

---

## ğŸ”¹ 6. Limpieza de coordenadas con *CoordinateCleaner*

```r
# Seleccionar columnas mÃ­nimas requeridas
clean_input <- occs_crop_df %>%
  select(
    species = scientificName,
    decimalLatitude,
    decimalLongitude,
    year
  ) %>%
  mutate(iso_a2 = "CL")

# Aplicar filtros sugeridos por Zizka et al. (2019)
cc_flags <- clean_coordinates(
  x = clean_input,
  lon = "decimalLongitude",
  lat = "decimalLatitude",
  species = "species",
  countries = "iso_a2",
  tests = c("capitals", "centroids", "equal", "gbif", "institutions",
            "seas", "zeros", "urban"),
  value = "flagged"
)

# Conservar solo los registros vÃ¡lidos
occs_limpias <- occs_crop_df[cc_flags, ]

# Guardar resultados
write.csv(occs_limpias, "data/occs_limpias.csv", row.names = FALSE)
```

---

## ğŸ”¹ 7. Resumen del flujo de trabajo

1. Cargar y filtrar especies vÃ¡lidas desde un catÃ¡logo local.  
2. Descargar registros de ocurrencia desde GBIF usando `rgbif`.  
3. Combinar y estandarizar los datasets.  
4. Recortar espacialmente al territorio continental chileno.  
5. Aplicar controles de calidad geogrÃ¡fica con `CoordinateCleaner`.  
6. Exportar el conjunto final de datos limpios.

---

## ğŸ”¹ 8. Referencias

- Zizka, A., Silvestro, D., Andermann, T. *et al.* (2019). **CoordinateCleaner: Standardized cleaning of occurrence records from biological collection databases.** *Methods in Ecology and Evolution*, 10, 744â€“751.  
- [GBIF API Documentation](https://www.gbif.org/developer/occurrence)  
- [rgbif R package](https://cran.r-project.org/package=rgbif)